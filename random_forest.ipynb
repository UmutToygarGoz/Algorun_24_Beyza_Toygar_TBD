{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92120f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data/train.csv\"\n",
    "products_file = \"data/products.csv\"\n",
    "holidays_file = \"data/holidays.csv\"\n",
    "sample_submission_file = \"data/sample_submission.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "products_df = pd.read_csv(products_file)\n",
    "holidays_df = pd.read_csv(holidays_file)\n",
    "sample_submission_df = pd.read_csv(sample_submission_file, delimiter=\"|\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train_df[\"week_starting_date\"] = pd.to_datetime(train_df[\"week_starting_date\"])\n",
    "test_df[\"week_starting_date\"] = pd.to_datetime(test_df[\"week_starting_date\"])\n",
    "sample_submission_df[\"week_starting_date\"] = pd.to_datetime(sample_submission_df[\"week_starting_date\"])\n",
    "merged_data = pd.merge(train_df, products_df, on=\"product_id\", how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf31c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dizii\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'merged_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13140\\1864437205.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Assuming merged_data is already loaded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"week_starting_date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"week_starting_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming merged_data is already loaded\n",
    "train_df = merged_data.copy()\n",
    "train_df[\"week_starting_date\"] = pd.to_datetime(train_df[\"week_starting_date\"])\n",
    "\n",
    "# Sort data by product_id and week_starting_date to ensure chronological order\n",
    "train_df.sort_values(by=[\"product_id\", \"week_starting_date\"], inplace=True)\n",
    "\n",
    "# Set negative sales to 0 (to handle invalid or erroneous negative values)\n",
    "train_df[\"sales_quantity\"] = train_df[\"sales_quantity\"].apply(lambda x: max(x, 0))\n",
    "\n",
    "# Create lag features for previous weeks' sales (lag 1, lag 2, etc.)\n",
    "for lag in range(1, 2):  # Using lags for 1 week, 2 weeks, etc.\n",
    "    train_df[f\"lag_{lag}_sales\"] = train_df.groupby('product_id')['sales_quantity'].shift(lag)\n",
    "\n",
    "# Create a feature for sales from the same week in the previous year (52 weeks ago)\n",
    "train_df[\"lag_52_sales\"] = train_df.groupby('product_id')['sales_quantity'].shift(53)\n",
    "\n",
    "# Drop rows with missing values (caused by lagging)\n",
    "train_df = train_df.dropna(subset=[f\"lag_{lag}_sales\" for lag in range(1, 2)] + [\"lag_52_sales\"])\n",
    "\n",
    "# Feature columns (lags including 1 year ago)\n",
    "features = [f\"lag_{lag}_sales\" for lag in range(1, 2)] + [\"lag_52_sales\"]\n",
    "\n",
    "# Target column (sales quantity)\n",
    "target = 'sales_quantity'\n",
    "\n",
    "# Filter out rows with non-positive sales quantities (if applicable)\n",
    "train_df = train_df[train_df[target] > 0]\n",
    "\n",
    "# Split into training and validation sets (80% train, 20% validation)\n",
    "X = train_df[features]\n",
    "y = train_df[target]\n",
    "\n",
    "# Retain product_id and week_starting_date for later use\n",
    "meta_columns = train_df[[\"product_id\", \"week_starting_date\"]]\n",
    "\n",
    "X_train, X_val, y_train, y_val, meta_train, meta_val = train_test_split(\n",
    "    X, y, meta_columns, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Initialize and train the Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Clip predictions to avoid negatives\n",
    "y_pred = np.maximum(y_pred, 0)\n",
    "\n",
    "# Add a small constant to avoid log(0) or negative values for RMSLE\n",
    "y_val = y_val + 1  # Adding 1 to both actual and predicted sales to avoid log(0)\n",
    "y_pred = y_pred + 1\n",
    "\n",
    "# Calculate RMSLE\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_val, y_pred))\n",
    "print(f\"Root Mean Squared Logarithmic Error (RMSLE): {rmsle:.4f}\")\n",
    "\n",
    "# Add predictions back to the validation metadata\n",
    "meta_val[\"sales_quantity\"] = y_pred - 1  # Subtract 1 to undo earlier constant addition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36baa2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sample_submission_df.copy()\n",
    "\n",
    "\n",
    "combined_df = pd.concat([train_df[[\"product_id\", \"week_starting_date\", \"sales_quantity\"]],\n",
    "                         test_df[[\"product_id\", \"week_starting_date\"]]], \n",
    "                        ignore_index=True)\n",
    "\n",
    "# Sort combined data by product_id and week_starting_date\n",
    "combined_df.sort_values(by=[\"product_id\", \"week_starting_date\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Fill missing sales_quantity for test rows with NaN (test rows will have this column missing)\n",
    "combined_df[\"sales_quantity\"] = combined_df[\"sales_quantity\"].fillna(np.nan)\n",
    "\n",
    "print(combined_df.head)\n",
    "\n",
    "# Create lag features\n",
    "for lag in range(1, 2):  # Lags: 1 week, 2 weeks, 3 weeks\n",
    "    combined_df[f\"lag_{lag}_sales\"] = combined_df.groupby('product_id')['sales_quantity'].shift(lag + 53)\n",
    "\n",
    "# Create a feature for sales from the same week in the previous year (52 weeks ago)\n",
    "combined_df[\"lag_52_sales\"] = combined_df.groupby('product_id')['sales_quantity'].shift(53)\n",
    "\n",
    "# Separate back the test set\n",
    "test_features = combined_df.loc[combined_df[\"sales_quantity\"].isna(), \n",
    "                                 [\"product_id\", \"week_starting_date\"] + [f\"lag_{lag}_sales\" for lag in range(1, 2)] + [\"lag_52_sales\"]]\n",
    "\n",
    "print(test_features.isna().sum())\n",
    "# Drop rows with missing lag values in the test set\n",
    "test_features = test_features.fillna(0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "X_test = test_features[[f\"lag_{lag}_sales\" for lag in range(1, 2)] + [\"lag_52_sales\"]]\n",
    "test_features[\"predicted_sales\"] = model.predict(X_test)\n",
    "\n",
    "# Clip negative predictions to 0\n",
    "test_features[\"predicted_sales\"] = test_features[\"predicted_sales\"].apply(lambda x: max(x, 0))\n",
    "\n",
    "# Final predicted test set\n",
    "final_test_predictions = test_features[[\"product_id\", \"week_starting_date\", \"predicted_sales\"]]\n",
    "\n",
    "print(final_test_predictions.head)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
